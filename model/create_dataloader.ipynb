{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f847f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# load CLIP's preprocess function\n",
    "_, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b84b37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|█████████████████████████| 1.39G/1.39G [01:01<00:00, 22.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 116008/116008 [00:10<00:00, 11393.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import load_dataset\n",
    "\n",
    "os.environ['EXTRACT_DIR'] = \"/tmp/GLAMI-1M/\"\n",
    "load_dataset.download_dataset(dataset_url=\"https://huggingface.co/datasets/glami/glami-1m/resolve/main/GLAMI-1M-dataset--test-only.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a3ada0",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfa48061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of products: 116004\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset.get_dataframe('test')[['item_id', 'image_id', 'name', 'description', 'category_name', 'image_file']].copy()\n",
    "print(f\"number of products: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "115ba7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images: 85577\n"
     ]
    }
   ],
   "source": [
    "# only need `category_name` and `image_file` feature\n",
    "# drop duplicate image \n",
    "df = df.drop_duplicates(subset=['image_file'])[['category_name', 'image_file']].reset_index(drop=True)\n",
    "print(f\"number of images: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15b1c2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training images: 13000\n",
      "number of training texts: 186\n"
     ]
    }
   ],
   "source": [
    "df_sample = df.sample(13000, random_state=41)\n",
    "print(f\"number of training images: {df_sample['image_file'].nunique()}\")\n",
    "print(f\"number of training texts: {df_sample['category_name'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bf01b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create more meaningful prompt for category name\n",
    "category_name_to_prompt = {}\n",
    "category_names = df_sample['category_name'].unique()\n",
    "for category_name in category_names:\n",
    "    human_readable_category_name = (category_name.strip()\n",
    "                                    .replace('women-s', \"women's\").replace('womens', \"women's\")\n",
    "                                    .replace('men-s', \"men's\").replace('mens', \"men's\").replace('-', ' ')\n",
    "                                    .replace(' and ', ' or '))\n",
    "    prompt = (\"A photo of a \" + human_readable_category_name + \", a type of fashion product\")\n",
    "    category_name_to_prompt[category_name] = prompt\n",
    "    \n",
    "df_sample['prompt'] = df_sample['category_name'].apply(lambda category_name: category_name_to_prompt[category_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b3029fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each category corresponds to an independent label\n",
    "category_name_to_label = {}\n",
    "for label, category_name in enumerate(category_names):\n",
    "    category_name_to_label[category_name] = label\n",
    "    \n",
    "df_sample['label'] = df_sample['category_name'].map(category_name_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84e2cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = []\n",
    "prompt_list = []\n",
    "label_list = []\n",
    "\n",
    "for row in df_sample.itertuples(index=True):\n",
    "    image = Image.open(row.image_file).convert(\"RGB\")\n",
    "    prompt = row.prompt\n",
    "    label = row.label\n",
    "\n",
    "    images_list.append(image)\n",
    "    prompt_list.append(prompt)\n",
    "    label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65fe7926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11000 training samples\n",
    "# 2000 test samples\n",
    "images_list_train = images_list[:11000]\n",
    "images_list_test = images_list[11000:]\n",
    "\n",
    "prompt_list_train = prompt_list[:11000]\n",
    "prompt_list_test = prompt_list[11000:]\n",
    "\n",
    "label_list_train =  label_list[:11000]\n",
    "label_list_test = label_list[11000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8af5e2",
   "metadata": {},
   "source": [
    "## Create `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b783f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, images_list, prompt_list, label_list, preprocess):\n",
    "        self.images_list = images_list\n",
    "        self.prompt_list = prompt_list\n",
    "        self.label_list = label_list\n",
    "        self.preprocess = preprocess\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images_list[idx]\n",
    "        image_tensor = self.preprocess(image)\n",
    "\n",
    "        prompt = self.prompt_list[idx]\n",
    "        prompt_token = clip.tokenize([prompt])[0]\n",
    "\n",
    "        label = self.label_list[idx]\n",
    "        return image_tensor, prompt_token, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a530bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FashionDataset(images_list_train, prompt_list_train, label_list_train, preprocess)\n",
    "test_dataset = FashionDataset(images_list_test, prompt_list_test, label_list_test, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b16e16e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensures no same label per batch\n",
    "\n",
    "class BalancedBatchSampler(BatchSampler):\n",
    "    \"\"\"\n",
    "    Returns batches of size n_classes * n_samples\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, labels, n_classes, n_samples):\n",
    "        self.labels = labels\n",
    "        self.labels_set = list(set(self.labels.numpy()))\n",
    "        self.label_to_indices = {label: np.where(self.labels.numpy() == label)[0]\n",
    "                                 for label in self.labels_set}\n",
    "        for l in self.labels_set:\n",
    "            np.random.shuffle(self.label_to_indices[l])\n",
    "        self.used_label_indices_count = {label: 0 for label in self.labels_set}\n",
    "        self.count = 0\n",
    "        self.n_classes = n_classes\n",
    "        self.n_samples = n_samples\n",
    "        self.n_dataset = len(self.labels)\n",
    "        self.batch_size = self.n_samples * self.n_classes\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.count = 0\n",
    "        while self.count + self.batch_size < self.n_dataset:\n",
    "            classes = np.random.choice(self.labels_set, self.n_classes, replace=False)\n",
    "            indices = []\n",
    "            for class_ in classes:\n",
    "                indices.extend(self.label_to_indices[class_][\n",
    "                               self.used_label_indices_count[class_]:self.used_label_indices_count[\n",
    "                                                                         class_] + self.n_samples])\n",
    "                self.used_label_indices_count[class_] += self.n_samples\n",
    "                if self.used_label_indices_count[class_] + self.n_samples > len(self.label_to_indices[class_]):\n",
    "                    np.random.shuffle(self.label_to_indices[class_])\n",
    "                    self.used_label_indices_count[class_] = 0\n",
    "            yield indices\n",
    "            self.count += self.n_classes * self.n_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_dataset // self.batch_size\n",
    "    \n",
    "train_labels = torch.tensor(label_list_train)\n",
    "train_sampler = BalancedBatchSampler(train_labels, BATCH_SIZE, 1)\n",
    "train_dataloader_sample_batch = DataLoader(train_dataset, batch_sampler=train_sampler)\n",
    "\n",
    "test_labels = torch.tensor(label_list_test)\n",
    "test_sampler = BalancedBatchSampler(test_labels, BATCH_SIZE, 1)\n",
    "test_dataloader_sample_batch = DataLoader(test_dataset, batch_sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1496c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data loader for training\n",
    "with open('data_loader/train_dataloader.pkl', 'wb') as f:\n",
    "    pickle.dump(train_dataloader_sample_batch, f)\n",
    "    \n",
    "with open('data_loader/test_dataloader.pkl', 'wb') as f:\n",
    "    pickle.dump(test_dataloader_sample_batch, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
